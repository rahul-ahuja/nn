{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Camera Calibration\n",
    "1. Have the camera matrix and distortion coefficients been computed correctly and\n",
    "checked on one of the calibration images as a test?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Camera Images are usually distorted especially the edges of the camera are bended. It is because the camera converts 2D images into 3D. We will use OpenCV chessboard camera calibration functions to get the distortion coefficient, camera matrix to undistort the road images using chessboard images. \n",
    "\"object points\", which are the actual (x, y, z) coordinates of the chessboard corners in the\n",
    "world are obtained....\n",
    "The chessboard is assumed to be fixed on the (x, y) plane at z=0, such that the object points are\n",
    "the same for each calibration image.\n",
    "Thus, *objp* is just a replicated array of coordinates, and *objpoints* is appended with a copy of it every time chessboard corners are successfully detected in a test image.\n",
    "imgpoints are appended with the (x, y) pixel position of each of the corners in the image plane with\n",
    "each successful chessboard detection. After that the output objpoints and imgpoints are used to compute the camera calibration and distortion coefficients using the cv2.calibrateCamera() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from collections import deque\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def camera_calibration(img):\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((6*9,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "    # Step through the list and search for chessboard corners\n",
    "    for idx, fname in enumerate(img):\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size,None,None)\n",
    "    return (ret, mtx, dist, rvecs, tvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "calibration_image_files = glob.glob(\"camera_cal/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ret, mtx, dist, rvecs, tvecs = camera_calibration(calibration_image_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use camera matrix and distortion coefficients to undistort the camera images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def img_undistort(img):\n",
    "    \n",
    "# Test undistortion on an image\n",
    "    dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chess = cv2.imread('camera_cal/calibration19.jpg')\n",
    "undistort_chess = cv2.undistort(chess, mtx, dist, None, mtx)\n",
    "#f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "##ax1.imshow(chess)\n",
    "#ax1.set_title('Original Image', fontsize=30)\n",
    "#ax2.imshow(undistort_chess)\n",
    "#ax2.set_title('Undistorted Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Has the distortion correction been correctly applied to each image?\n",
    "In the below you can find the undistorted image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "road = cv2.imread('test_images/test5.jpg')\n",
    "road = cv2.cvtColor(road, cv2.COLOR_BGR2RGB)\n",
    "undistort_road = cv2.undistort(road, mtx, dist, None, mtx)\n",
    "#f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "#ax1.imshow(road)\n",
    "#ax1.set_title('Original Image', fontsize=30)\n",
    "#ax2.imshow(undistort_road)\n",
    "#ax2.set_title('Undistorted Image', fontsize=30#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def histogram_equal(img):\n",
    "    return cv2.equalizeHist(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gaussian_blur(img, kernel_size=5):\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 1280, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "road.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to get the gradients of the image in order to get edges and detect the lane lines. The fact that lane lines are vertical we can use Sobel operator in x or/and y direction in order to get the edges of the lane lines. Taking the gradient in the x-direction emphasizes edges closer to vertical and in the y-direction, edges closer to horizontal. As it can be seen that after appyling thresholded sobelx operator we obtained binary image but left lanes are missing under the yellow shade. That's why we have to change the colorspace in order to get the yellow lanes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hls_threshold(img, threshold = (180, 255)):\n",
    "    \n",
    "    hls_img = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    s_channel = hls_img[:,:,2]\n",
    "    s_channel = cv2.equalizeHist(s_channel)\n",
    "    binary = np.zeros_like(s_channel)\n",
    "    binary[(s_channel > threshold[0]) & (s_channel <= threshold[1])] = 1\n",
    "    #plt.imshow(hls_img)\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below picture it can be seen that binary thresholded s_channel is not good at detecting the white channels. But binary thresholded sobelx can detect the white lines. It will be better to stack these two binary images to get the robust lane detection algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s_channel_img = hls_threshold(undistort_road)\n",
    "#plt.imshow(s_channel_img,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(img, orient='x', sobel_kernel = 3, thresh_min=50, thresh_max=255):\n",
    "    \n",
    "#You need to pass a single color channel to the cv2.Sobel() function, so first convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    #gray = histogram_equal(gray)\n",
    "#Calculate the derivative in the x-direction (the 1, 0 at the end denotes x-direction):\n",
    "    #Calculate the derivative in the x-direction (the 1, 0 at the end denotes x-direction)\n",
    "    if orient == 'x':\n",
    "        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "        #Calculate the absolute value of the x-derivative\n",
    "        abs_sobel = np.absolute(sobelx)\n",
    "    if orient == 'y':\n",
    "        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "        #Calculate the absolute value of the y-derivative\n",
    "        abs_sobel = np.absolute(sobely)\n",
    "\n",
    "#Calculate the absolute value of the x-derivative:\n",
    "    #abs_sobel = np.absolute(sobelx)\n",
    "#Convert the absolute value image to 8-bit:\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "#Create a binary threshold to select pixels based on gradient strength:\n",
    "    sobel_binary = np.zeros_like(scaled_sobel)\n",
    "    sobel_binary[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "    #plt.imshow(sxbinary, cmap='gray')\n",
    "    return sobel_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sobelx_img = abs_sobel_thresh(undistort_road)\n",
    "#plt.imshow(sobelx_img,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mag_thresh(img, sobel_kernel=3, mag_thresh=(50, 255)):\n",
    "    # Calculate gradient magnitude\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    #gray = histogram_equal(gray)\n",
    "    \n",
    "    # Take both Sobel x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    # Apply threshold\n",
    "    # Rescale to 8 bit\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8) \n",
    "    # Create a binary image of ones where threshold is met, zeros otherwise\n",
    "    mag_binary = np.zeros_like(gradmag)\n",
    "    mag_binary[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 1\n",
    "\n",
    "    return mag_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mag_thresh_img = mag_thresh(undistort_road)\n",
    "#plt.imshow(mag_thresh_img,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to threshold an image for a given range and Sobel kernel\n",
    "def dir_threshold(img, sobel_kernel=15, thresh=(0.7, 1.7)):\n",
    "    # Grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    #gray = histogram_equal(gray)\n",
    "    # Calculate the x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Take the absolute value of the gradient direction, \n",
    "    # apply a threshold, and create a binary image result\n",
    "    absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    binary_output =  np.zeros_like(absgraddir)\n",
    "    binary_output[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dir_threshold_img = dir_threshold(undistort_road)\n",
    "#plt.imshow(dir_threshold_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combined_thresh(img):\n",
    "    abs_bin = abs_sobel_thresh(img, orient='x', thresh_min=50, thresh_max=255)\n",
    "    mag_bin = mag_thresh(img, sobel_kernel=3, mag_thresh=(50, 255))\n",
    "    dir_bin = dir_threshold(img, sobel_kernel=15, thresh=(0.7, 1.3))\n",
    "    hls_bin = hls_threshold(img, threshold=(170, 255))\n",
    "    combined = np.zeros_like(dir_bin)\n",
    "    combined[(abs_bin == 1 | ((mag_bin == 1) & (dir_bin == 1))) | hls_bin == 1] = 1     \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined_thresh_img = combined_thresh(undistort_road)\n",
    "#plt.imshow(combined_thresh_img,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_color_grad(s_channel_binary, sobelx_binary):\n",
    "# This returns a stack of the two binary images, whose components you can see as different colors\n",
    "    color_binary = np.dstack(( np.zeros_like(sobelx_binary), sobelx_binary, s_channel_binary))\n",
    "# Combine the two binary thresholds\n",
    "    combined_binary = np.zeros_like(sobelx_binary)\n",
    "    combined_binary[(s_channel_binary == 1) | (sobelx_binary == 1)] = 1\n",
    "    return combined_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined_binary_img = combine_color_grad(s_channel_img, sobelx_img)\n",
    "#plt.imshow(combined_binary_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined_binary_img = cv2.equalizeHist(combined_binary_img)\n",
    "#plt.imshow(combined_binary_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def region_of_interest(image):\n",
    "    bottom_left = (image.shape[1] * 0.15, image.shape[0])\n",
    "    bottom_right = (image.shape[1] * 0.93, image.shape[0])\n",
    "\n",
    "    top_left = (image.shape[1] * 0.4 , image.shape[0]/2)\n",
    "    top_right = (image.shape[1] * 0.6 , image.shape[0]/2)\n",
    "    \n",
    "    \n",
    "    white = np.zeros_like(image)\n",
    "    points = np.array([[bottom_left, top_left, top_right, bottom_right]], dtype=np.int32)\n",
    "    cv2.fillPoly(white, points , 255)\n",
    "    \n",
    "    masked_image = cv2.bitwise_and(image, white)\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 1280)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_binary_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.imshow(region_of_interest(combined_binary_img),cmap='gray')\n",
    "#plt.imshow(region_of_interest(combined_thresh_img),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def warp(img):\n",
    "    \n",
    "    img_size = (img.shape[1],img.shape[0])\n",
    "    src = np.float32(\n",
    "        [[(img_size[0] / 2) - 55, img_size[1] / 2 + 100],  #top-left\n",
    "        [((img_size[0] / 6) - 10), img_size[1]],           #bottom-left\n",
    "        [(img_size[0] * 5 / 6) + 60, img_size[1]],         #bottom-right\n",
    "        [(img_size[0] / 2 + 55), img_size[1] / 2 + 100]])  #top-right\n",
    "    dst = np.float32(\n",
    "        [[(img_size[0] / 4), 0],\n",
    "        [(img_size[0] / 4), img_size[1]],\n",
    "        [(img_size[0] * 3 / 4), img_size[1]],\n",
    "        [(img_size[0] * 3 / 4), 0]])\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    \n",
    "    warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#binary_warp = warp(region_of_interest(combined_thresh_img))\n",
    "binary_warp = warp((combined_thresh_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.imshow(binary_warp, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def histogram_filter(binary_warped):\n",
    "# Assuming you have created a warped binary image called \"binary_warped\"\n",
    "# Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]/2:,:], axis=0)\n",
    "    #plt.plot(histogram)\n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.plot(histogram_filter(binary_warp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def three_channel_binary(binary_warp):\n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    out_img = np.dstack((binary_warp, binary_warp, binary_warp))*255\n",
    "    return out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.imshow(three_channel_binary(binary_warp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def peaks(histogram, binary_warped):\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])  #co-ordinate of left lane\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint  #co-ordinate of right lane \n",
    "# Set height of windows\n",
    "    window_height = np.int(binary_warped.shape[0]/nwindows)  #height of the sqaure\n",
    "# Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()  #arrays with white pixels\n",
    "    nonzeroy = np.array(nonzero[0])    #y-arrays with white pixels\n",
    "    nonzerox = np.array(nonzero[1])    #x-arrays with white pixels\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    \n",
    "    return (nonzeroy, nonzerox, window_height, leftx_current, rightx_current, midpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Choose the number of sliding windows\n",
    "nwindows = 9\n",
    "#peaks(histogram_filter(binary_warp), binary_warp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rahul/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:4: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "nonzeroy, nonzerox, window_height, leftx_current, rightx_current, midpoint = peaks(histogram_filter(binary_warp), binary_warp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the width of the windows +/- margin\n",
    "margin = 100 #200 is the width of the window\n",
    "# Set minimum number of pixels found to recenter window\n",
    "minpix = 50\n",
    "def sliding_window(binary_warped, leftx_current, rightx_current, window_height, nonzeroy, nonzerox):\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "    # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "    # Draw the windows on the visualization image\n",
    "        #cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        #cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2)\n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "    # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "    # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    return (leftx, lefty, rightx, righty)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "leftx, lefty, rightx, righty = sliding_window(binary_warp, leftx_current, rightx_current, window_height, nonzeroy, nonzerox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def curvature(leftx,rightx,lefty,righty):\n",
    "    \n",
    "    #ploty = np.linspace(0, 719, num=720)# to cover same y-range as image\n",
    "\n",
    "    leftx = leftx[::-1]  # Reverse to match top-to-bottom in y\n",
    "    rightx = rightx[::-1]  # Reverse to match top-to-bottom in y\n",
    "    y_eval = 719 # 720p video/image, so last (lowest on screen) y index is 719\n",
    "\n",
    "# Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "# Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "# Calculate the new radii of curvature\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "# Now our radius of curvature is in meters\n",
    "    #print(left_curverad, 'm', right_curverad, 'm')\n",
    "    return (left_curverad, right_curverad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6576.7194062742192, 1820.2179689360528)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curvature(leftx,rightx,lefty,righty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_poly(lefty, leftx, righty, rightx):\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    return (left_fit,right_fit)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(left_fit,right_fit) = get_poly(lefty, leftx, righty, rightx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_shade(left_fit,right_fit, binary_warped):\n",
    "# Fit a second order polynomial to each\n",
    "    #left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    #right_fit = np.polyfit(righty, rightx, 2)\n",
    "    # Generate x and y values for plotting\n",
    "    fity = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    fit_leftx = left_fit[0]*fity**2 + left_fit[1]*fity + left_fit[2]\n",
    "    fit_rightx = right_fit[0]*fity**2 + right_fit[1]*fity + right_fit[2]\n",
    "    warp_zero = np.zeros_like(binary_warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    ploty = np.linspace(0, 719, num=720)# to cover same y-range as image\n",
    "# Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([fit_leftx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([fit_rightx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    return color_warp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.imshow(fill_shade(left_fit,right_fit, binary_warp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unwarp(img):\n",
    "    \n",
    "    img_size = (img.shape[1],img.shape[0])\n",
    "    src = np.float32(\n",
    "        [[(img_size[0] / 2) - 55, img_size[1] / 2 + 100],  #top-left\n",
    "        [((img_size[0] / 6) - 10), img_size[1]],           #bottom-left\n",
    "        [(img_size[0] * 5 / 6) + 60, img_size[1]],         #bottom-right\n",
    "        [(img_size[0] / 2 + 55), img_size[1] / 2 + 100]])  #top-right\n",
    "    dst = np.float32(\n",
    "        [[(img_size[0] / 4), 0],\n",
    "        [(img_size[0] / 4), img_size[1]],\n",
    "        [(img_size[0] * 3 / 4), img_size[1]],\n",
    "        [(img_size[0] * 3 / 4), 0]])\n",
    "    M = cv2.getPerspectiveTransform(dst, src)\n",
    "    \n",
    "    newwarped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    return newwarped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unwarped_shaded = unwarp(fill_shade(left_fit,right_fit, binary_warp))\n",
    "#plt.imshow(unwarped_shaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shaded_image(dst, newwarp):\n",
    "    return cv2.addWeighted(dst, 1, newwarp, 0.3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.imshow(shaded_image(undistort_road, unwarped_shaded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Line:\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100 #200 is the width of the window\n",
    "# Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "\n",
    "    \n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # x values of the last n fits of the line\n",
    "        self.left_fit = None\n",
    "        self.right_fit = None\n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None     \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.polyA_left = deque(maxlen=5)\n",
    "        self.polyB_left = deque(maxlen=5)\n",
    "        self.polyC_left = deque(maxlen=5)\n",
    "        \n",
    "        self.polyA_right = deque(maxlen=5)\n",
    "        self.polyB_right = deque(maxlen=5)\n",
    "        self.polyC_right = deque(maxlen=5)\n",
    "        \n",
    "        #self.left_fit = None\n",
    "        #self.right_fit = None\n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]  \n",
    "        #radius of curvature of the line in some units\n",
    "        #self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        #self.line_base_pos = None \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        #self.diffs = np.array([0,0,0], dtype='float') \n",
    "        #x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None\n",
    "        \n",
    "    def undetected_frame(self, binary_warped):\n",
    "        if self.detected == False:\n",
    "            histogram = np.sum(binary_warped[binary_warped.shape[0]/2:,:], axis=0)\n",
    "            window_height = np.int(binary_warped.shape[0]/nwindows)\n",
    "                # Identify the x and y positions of all nonzero pixels in the image\n",
    "            nonzero = binary_warped.nonzero()  #arrays with white pixels\n",
    "            nonzeroy = np.array(nonzero[0])    #y-arrays with white pixels\n",
    "            nonzerox = np.array(nonzero[1])    #x-arrays with white pixels\n",
    "            leftx_base = np.argmax(histogram[:midpoint])\n",
    "            rightx_base = np.argmax(histogram[midpoint:]) + midpoint  #co-ordinate of right lane \n",
    "            rightx_current = rightx_base\n",
    "            leftx_current = leftx_base\n",
    "            left_lane_inds = []\n",
    "            right_lane_inds = []\n",
    "            for window in range(nwindows):\n",
    "    # Identify window boundaries in x and y (and right and left)\n",
    "                win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "                win_y_high = binary_warped.shape[0] - window*window_height\n",
    "                win_xleft_low = leftx_current - margin\n",
    "                win_xleft_high = leftx_current + margin\n",
    "                win_xright_low = rightx_current - margin\n",
    "                win_xright_high = rightx_current + margin\n",
    "    # Draw the windows on the visualization image\n",
    "        #cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        #cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2)\n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "                good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "                good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "    # Append these indices to the lists\n",
    "            left_lane_inds.append(good_left_inds)\n",
    "            right_lane_inds.append(good_right_inds)\n",
    "    # If you found > minpix pixels, recenter next window on their mean position\n",
    "            if len(good_left_inds) > minpix:\n",
    "                leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "            if len(good_right_inds) > minpix:        \n",
    "                rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "    # Concatenate the arrays of indices\n",
    "            left_lane_inds = np.concatenate(left_lane_inds)\n",
    "            right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    # Extract left and right line pixel positions\n",
    "            leftx = nonzerox[left_lane_inds]\n",
    "            lefty = nonzeroy[left_lane_inds] \n",
    "            rightx = nonzerox[right_lane_inds]\n",
    "            righty = nonzeroy[right_lane_inds]\n",
    "            left_fit = np.polyfit(lefty, leftx, 2)\n",
    "            right_fit = np.polyfit(righty, rightx, 2)\n",
    "            return (left_fit, right_fit)\n",
    "            #return (leftx,lefty,rightx,righty)\n",
    "                \n",
    "    def detected_frame(self, binary_warped,left_fit,right_fit):\n",
    "        nonzero = binary_warped.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "        right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
    "            # Again, extract left and right line pixel positions\n",
    "\n",
    "        leftx = nonzerox[left_lane_inds]\n",
    "        lefty = nonzeroy[left_lane_inds] \n",
    "        rightx = nonzerox[right_lane_inds]\n",
    "        righty = nonzeroy[right_lane_inds]\n",
    "# Fit a second order polynomial to each\n",
    "        left_fit = np.polyfit(lefty, leftx, 2)\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "        return (left_fit,right_fit)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "line = Line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#line.undetected_frame(binary_warp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "        \n",
    "    undistorted = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "        \n",
    "    combined_binary_img = combined_thresh(undistorted)\n",
    "    binary_warp = warp(combined_binary_img)    \n",
    "        #nonzeroy, nonzerox, window_height, leftx_current, rightx_current, midpoint = peaks(histogram_filter(binary_warp),\n",
    "        #                                                                               binary_warp)\n",
    "        #leftx, lefty, rightx, righty = sliding_window(binary_warp,\n",
    "        #                                              leftx_current, rightx_current, window_height, nonzeroy, nonzerox)\n",
    "        #(left_fit,right_fit) = get_poly(lefty, leftx, righty, rightx)\n",
    "    if line.detected == True:\n",
    "        nonzero = binary_warp.nonzero()\n",
    "        if nonzero[1] == []:\n",
    "            line.detected = False\n",
    "        else:\n",
    "            line.left_fit = line.detected_frame(binary_warp, line.left_fit, line.right_fit)[0]\n",
    "            line.right_fit = line.detected_frame(binary_warp, line.left_fit, line.right_fit)[1]\n",
    "    \n",
    "    if line.detected == False:\n",
    "        \n",
    "        line.left_fit = line.undetected_frame(binary_warp)[0]\n",
    "        line.right_fit = line.undetected_frame(binary_warp)[1]\n",
    "        line.detected = True\n",
    "        #print(line.left_fit,line.right_fit)\n",
    "    line.polyA_left.append(line.left_fit[0])\n",
    "    line.polyB_left.append(line.left_fit[1])\n",
    "    line.polyC_left.append(line.left_fit[2])\n",
    "    \n",
    "    A_average_poly_left = sum(line.polyA_left) / len(line.polyA_left)\n",
    "    B_average_poly_left = sum(line.polyB_left) / len(line.polyB_left)\n",
    "    C_average_poly_left = sum(line.polyC_left) / len(line.polyC_left)\n",
    "    \n",
    "    line.polyA_right.append(line.right_fit[0])\n",
    "    line.polyB_right.append(line.right_fit[1])\n",
    "    line.polyC_right.append(line.right_fit[2])\n",
    "    \n",
    "    A_average_poly_right = sum(line.polyA_right) / len(line.polyA_right)\n",
    "    B_average_poly_right = sum(line.polyB_right) / len(line.polyB_right)\n",
    "    C_average_poly_right = sum(line.polyC_right) / len(line.polyC_right)\n",
    "    \n",
    "    fity = np.linspace(0, binary_warp.shape[0]-1, binary_warp.shape[0])\n",
    "    fit_leftx = A_average_poly_left*fity**2 + B_average_poly_left*fity + C_average_poly_left\n",
    "    fit_rightx = A_average_poly_right*fity**2 + B_average_poly_right*fity + C_average_poly_right\n",
    "    warp_zero = np.zeros_like(binary_warp).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    ploty = np.linspace(0, 719, num=720)# to cover same y-range as image\n",
    "# Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([fit_leftx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([fit_rightx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    #print (line.polyA)\n",
    "    return color_warp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "road2 = cv2.imread('test_images/test6.jpg')\n",
    "road2 = cv2.cvtColor(road, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rahul/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:42: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0b55f206a0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgUAAAEzCAYAAAChV3AgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0b55f33ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow((process_image(road)))\n",
    "#(process_image(road2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line.detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video project.mp4\n",
      "[MoviePy] Writing video project.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1260/1261 [09:30<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project.mp4 \n",
      "\n",
      "CPU times: user 33min 5s, sys: 48.1 s, total: 33min 53s\n",
      "Wall time: 9min 32s\n"
     ]
    }
   ],
   "source": [
    "output = 'project.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print (line.recent_xfitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
